{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc7807a-26c4-4ef2-9ad5-aaa54d96d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installiamo le librerie necessarie\n",
    "!pip install --upgrade --quiet langchain\n",
    "!pip install --upgrade --quiet langchain_openai\n",
    "!pip install --upgrade --quiet langchain_chroma\n",
    "!pip install --upgrade --quiet langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058fd31e-b37c-44d3-b010-a60a6117e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carichiamo l'API Key di OpenAI\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'xxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f95095b-4ebf-45cb-b6b1-110d72fcfa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usiamo il Document Loader per caricare il video\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"./i_promessi_sposi.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb5388cd-75b1-4fbb-97e2-c15a33294b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il nostro documento è troppo grande per entrare nella context windows di GPT\n",
    "# Usiamo un text spliltter per dividerlo in documenti più piccoli\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=5000,\n",
    ")\n",
    "documents = text_splitter.split_documents(documents)\n",
    "print(f\"Diviso il testo in {len(documents)} documenti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7fdc1b6-b0ee-4abc-afb2-727a8b73de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usiamo il prompt template di langchain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "\t(\"user\", \"\"\"\n",
    "Utilizza il contenuto del testo fornito per rispondere alla domanda dell'utente. Rispondi che non conosci la risposta se non è contenuta nel testo.\n",
    "Domanda: {question}\n",
    "\t \n",
    "Testo:\n",
    "{text}\n",
    "\"\"\")\n",
    "])\n",
    "\n",
    "# Ora possiamo invocare GPT per generare il riassunto.\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# riscriviamo l'ultima parte usando le chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain = ({\"text\": RunnablePassthrough(), \"question\": RunnablePassthrough()} | prompt_template | llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f103485-301b-43c0-b348-d9717baedda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don Abbondio era il curato di una delle terre accennate nel testo. Non si conosce il nome specifico di questa terra né il casato del personaggio, poiché non sono presenti nel manoscritto.\n"
     ]
    }
   ],
   "source": [
    "# Inserisci una domanda relativa al contenuto del testo\n",
    "question = \"Chi era Don Abbondio?\"\n",
    "\n",
    "# Eseguiamo la chain\n",
    "answer = chain.invoke({\"text\": documents[0].page_content, \"question\": question})\n",
    "\n",
    "# Stampiamo il risultato\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c582f-d0b0-4929-a63b-50d5c46ebe3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
